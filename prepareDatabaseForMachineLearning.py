import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time
import math
from multiprocessing import Process, Queue


def prepareDatabseForMachineLearning(data, orderOfMatrix, R0=100.0, filename = False, giveUpdates = True):
    """
    A function which takes a generated dataframe and prepares it for machine learning by making the proximity matrices and calculating their eigenvalues.
    
    data is the dataframe (as generated by makeRandomDatabase) for which the eigenvalues of the proximity matrices should be calculated.
    orderOfMatrix is a list of the 'order' (power to which the relative distance is taken) for each proximity matrix.
    filename is the name of the file the database get's exported to. The .json file extension get's added in the code itself. If the type of filename is not a string no file will be saved.
    giveUpdates is a boolean which determines if updates about the progress of the database preperation get's printed.
    """
    
    timeStart = time.time()
    data = data.reset_index()
    numberOfDatapoints = len(data['particleCoordinates'])
    eigenvalues = []
    relativeDistances = []
    
    for a in range(0, numberOfDatapoints):
        # Loop trough each datapoint
        coordinates = data['particleCoordinates'][a]
        dimension = len(coordinates[0])
        widthOfCell = data['widthOfCell'][a]
        depthOfSurroundingCells = math.ceil(R0 / widthOfCell + 1)
        
        eigenvaluesRow = []
        relativeDistancesRow = [widthOfCell]
        
        for order in orderOfMatrix:
            # For each order of eigenvalues wanted a matrix is constructed.
            matrix = np.zeros((len(coordinates), len(coordinates)))
            relativeDistancesRowOrder = []# The relative distances are also calculated and saved.
            
            for i in range(0, len(coordinates)):
                for j in range(i, len(coordinates)):
                    # Loop trough all matrix elements and define their proximity and relative distances.
                    sumOfProximity = 0
                    
                    if (not i==j):
                        # This part calculates the relative distance inputs.
                        vectorA = coordinates[i]
                        vectorB = coordinates[j]
                        differenceVector = vectorA - vectorB
                        relativeDistancesRowOrder.append(np.sqrt(differenceVector.dot(differenceVector))**(-order))
                    
                    cellCoordinates = [-depthOfSurroundingCells for k in range(dimension)]
                    
                    while True:
                        # The while loop is to make sure that each coordinate in any amount of dimensions is taken into account.
                        for k in range(len(cellCoordinates)):
                            if cellCoordinates[k]>depthOfSurroundingCells:
                                # If a cellCoordinate is large then the depth of the surrounding cells then make it minimal again and increase the next coordinate by one. Thus you will loop trough each possible permutation.
                                cellCoordinates[k + 1] = cellCoordinates[k + 1] + 1
                                cellCoordinates[k] = -depthOfSurroundingCells
                        
                        if not (i == j and sum([0==cellCoordinate for cellCoordinate in cellCoordinates])==dimension):
                            # Calculate the addition to the proximity matrix element.
                            vectorA = coordinates[i]
                            vectorB = coordinates[j] + widthOfCell * np.array(cellCoordinates)# Also take into account the mirror images in the other surrounding cells.
                            differenceVector = vectorA - vectorB
                            distance = np.sqrt(differenceVector.dot(differenceVector))
                            
                            if distance < R0:
                                sumOfProximity = sumOfProximity + ((R0 / distance) - (distance / R0))**(-order)
                        
                        if sum(cellCoordinates)==dimension*depthOfSurroundingCells:
                            # If all cell coordinates are maximal the sum of it should be the dimension times the depth of surrounding cells and then the while loop should be stopped.
                            break
                        
                        cellCoordinates[0] = cellCoordinates[0] + 1# Iterate the first cell coordinate.
                    
                    matrix[i][j] = sumOfProximity
            
            for i in range(0, len(coordinates)):
                for j in range(0, i):
                    # Since the matrix is symetric make sure that you don't do the same calculation twice.
                    matrix[i][j] = matrix[j][i]
            
            eigenvalue, eigenVector = np.linalg.eig(matrix)
            [eigenvaluesRow.append(i) for i in sorted(eigenvalue)]
            #[eigenvaluesRow.append(i) for i in eigenvalue]
            
            [relativeDistancesRow.append(i) for i in sorted(relativeDistancesRowOrder)]
        
        #eigenvalues.append(sorted(eigenvaluesRow))
        eigenvalues.append(eigenvaluesRow)
        relativeDistances.append(relativeDistancesRow)
        
        if giveUpdates:
            expectedTimeLeft = (numberOfDatapoints - 1 - a) / ((a + 1) / (time.time() - timeStart))
            print(str(math.ceil(100 * (a + 1) / (numberOfDatapoints))).rjust(3, ' '), '% done, expected time left', math.ceil(expectedTimeLeft), 'seconds,', math.ceil(time.time() - timeStart), 'seconds since start.')
    
    data['eigenvalues'] = eigenvalues
    data['relativeDistances'] = relativeDistances
    
    if type(filename) == str:
        # If wanted save the data to a json file.
        dataDF.to_json(filename + '.json', orient='columns')
    
    return data


def prepareDatabseForMachineLearningSingleQueue(q, data, orderOfMatrix, R0, giveUpdates):
    q.put(prepareDatabseForMachineLearning(data, orderOfMatrix, R0, False, giveUpdates))


def prepareDatabseForMachineLearningMultiprocessing(data, orderOfMatrix, R0=4.0, filename = False, amountOfProcesses = 5):
    """
    A function which impliments multiprocessing for the prepareDatabseForMachineLearning function.
    """
    q = Queue()
    processes = []
    splitData = np.array_split(data, amountOfProcesses)
    print('Using multiprocessing only the first procces gives updates')
    
    processes.append(Process(target = prepareDatabseForMachineLearningSingleQueue, args = (q, splitData[0], orderOfMatrix, R0, True)))
    
    for i in range(1, amountOfProcesses):
        processes.append(Process(target = prepareDatabseForMachineLearningSingleQueue, args = (q, splitData[i], orderOfMatrix, R0, False)))
        
    for i in processes:
        i.start()
    
    dataDF = pd.concat([q.get() for i in range(0, amountOfProcesses)], ignore_index = True, sort = False)
    
    if type(filename) == str:
        # If wanted save the data to a json file.
        dataDF.to_json(filename + '.json', orient='columns')
    
    return dataDF